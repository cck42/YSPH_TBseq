import pandas as pd
import os

configfile: "config/config.yaml"
include: "rules/common.py"

#RUNDATE=config['rundate']
#SAMPLES = set(pd.read_table(config['samples'],header=0,dtype=str,delimiter=',')['Seq_ID']) #change from 'strain' as applicable
#SAMPLES=config['samples'] #un-comment for testing with single samples
#PATHS=set(pd.read_table(config['seq_data'],dtype=str))
#REFERENCE=config['reference']
#HOMEDIR=config['homedir'] #only if you want to set to something other than where this will be run from
#SCRATCH=config['scratchdir']
#PRIMERS=config['primers']
#OUTDIR=config['outdir']


SAMPLES = set(pd.read_table(config['samples'],header=0,dtype=str,delimiter=',').loc[lambda df: df['NGS_Date'] == config['rundate'], 'Seq_ID'].tolist())
READ_SUBSAMPLES=set(config['read_subsamples'])

container: "docker://sethnr/pgcoe_bacseq:0.01"



rule all:
    input:
        #coveragestats=expand(os.path.join(config['outdir'],'align/{sample}_coverage_sub{subsample}.tsv'),
	#                     sample=SAMPLES,subsample=READ_SUBSAMPLES),
        consensuses=expand(os.path.join(config['outdir'],'ivar/{sample}_consensus.fa'),sample=SAMPLES),
        ivariants=expand(os.path.join(config['outdir'],'ivar/{sample}_ivariants.tsv'),sample=SAMPLES),
        pileupvcf=os.path.join(config['outdir'],'pileup',"all_variants_filt.vcf.gz"),
        snippyvcf=config['outdir']+'/snippy/core.vcf',
        combinedcoverage=os.path.join(config['outdir'],config['runname'],'combinedcoverage.tsv'),
        basedepth=config['outdir']+'/'+config['runname']+'/all_depth.txt',
        evorha=expand(config['outdir']+'/evorha/{sample}.hapfreq',sample=SAMPLES)
    output:
        snippyvcf=config['outdir']+'/'+config['runname']+'/snippy_all_vars.vcf',
        pileupvcf=config['outdir']+'/'+config['runname']+'/pileup_all_vars.vcf.gz',
    shell:
        """
	cp {input.snippyvcf} {output.snippyvcf}
	cp {input.pileupvcf} {output.pileupvcf}
	"""


rule indexref:
    input:
        reference=config['reference']
    output:
        indexedref="data/reference.fasta.amb"
    log:
    message: "Indexing H37Rv reference"
    shell:
        """
        bwa index {input.reference}
        """

rule align_to_ref:
    input:
        read_location=os.path.join(config['readdir'],'{sample}'),
        indexedref="data/reference.fasta.amb"
    params:
        ref=config['reference']
    output:
        aligned = os.path.join(config['outdir'],'align/{sample}_aligned.bam') # .bam file output of aligned and sorted reads
    log:
        stdout="logs/bwa/{sample}_aln.out",
        stderr="logs/bwa/{sample}_aln.err"
    container: "docker://sethnr/pgcoe_bacseq:0.01"
    message: "Aligning reads to H37Rv and sorting output for sample {wildcards.sample}"
    shell:
        """
        echo "Aligning reads for {wildcards.sample} to H37Rv reference strain\n"
        echo 'bwa mem {params.ref} {input.read_location}/*R1* {input.read_location}/*R2* | samtools view -b -F 4 -F 2048 | samtools sort -o {wildcards.sample}_aln.bam\n' 
        bwa mem {params.ref} {input.read_location}/*R1* {input.read_location}/*R2* | samtools view -b -F 4 -F 2048 | samtools sort -o {output.aligned} >> {log.stdout} 2>> {log.stderr}
        """

rule primerclip:
    input:
        aligned = os.path.join(config['outdir'],'align/{sample}_aligned.bam'),
        primers = config['primers']
    output:
        aln_trimmed= os.path.join(config['outdir'],'align/{sample}_aln_itrim.bam')
    log:
        stdout="logs/ivar/{sample}_trim.out",
        stderr="logs/ivar/{sample}_trim.err"
    message: "QC and soft-clipping primers using iVar"
    shell:
        """
        ivar trim -i {input.aligned} -b {input.primers} -p {output.aln_trimmed} -e > {log.stdout} 2> {log.stderr}
        """

rule sort:
    input:
        aln_trimmed= os.path.join(config['outdir'],'align/{sample}_aln_itrim.bam')
    output:
        aln_itrim_sorted=os.path.join(config['outdir'],'align/{sample}_aln_itrim_sorted.bam')
    log:
        stdout="logs/align/{sample}_sort.out",
        stderr="logs/align/{sample}_sort.err"
    message: "Sorting and indexing reads"
    shell:
        """
        samtools sort {input.aln_trimmed} -o {output.aln_itrim_sorted} > {log.stdout} 2> {log.stderr}
        samtools index {output.aln_itrim_sorted} >> {log.stdout} 2>> {log.stderr}
        """

rule subsample:
    input:
        aln_itrim_sorted= os.path.join(config['outdir'],'align/{sample}_aln_itrim_sorted.bam')
    output:
        subsamp=os.path.join(config['outdir'],'align/{sample}_subsamp{subsample}.bam')
    log:
        stdout="logs/align/{sample}_sub_{subsample}.out",
        stderr="logs/align/{sample}_sub_{subsample}.err",
    message: "Selecting subsample of reads from {wildcards.sample}: {wildcards.subsample}"
    shell:
        """
        samtools view -b -s {wildcards.subsample} {input.aln_itrim_sorted} -o {output.subsamp} 1> {log.stdout} 2> {log.stderr}
        """

rule coverage:
    input:
        subsamp=os.path.join(config['outdir'],'align/{sample}_subsamp{subsample}.bam')
    output:
        coveragestats=os.path.join(config['outdir'],'align/{sample}_coverage_sub{subsample}.tsv')
    params:
        maxdepth=0,
        minmapqual=60,
        minbasequal=13
    log:
        stderr="logs/align/{sample}_sub{subsample}.err"
    message: "Computing coverage of reference for sample {wildcards.sample} with a read subsample fraction of {wildcards.subsample}"
    shell:
        """
        printf '%s\\t%s\\t%s\\t%s\\t%s\\t%s\\t%s\\t%s\\t%s\\t%s\\t%s\\n' {wildcards.sample} {wildcards.subsample} `samtools coverage -d {params.maxdepth} -q {params.minmapqual} -Q {params.minbasequal} --no-header {input.subsamp}` > {output.coveragestats} 2> {log.stderr}
        """

rule mdepth:
    input:
        bams=expand(os.path.join(config['outdir'],'align/{sample}_aln_itrim_sorted.bam'),sample=SAMPLES)
    output:
        config['outdir']+'/'+config['runname']+'/all_depth.txt'
    params:
        maxdepth=0,
        minmapqual=60,
        minbasequal=13
    log:
        stderr="logs/depth/"+config['runname']+".err"
    shell:
        """
        samtools depth -a -H {input.bams} -o {output} 2>&1 >  {log.stderr}
        """


rule combinedcoverage:
    input:
        coveragestats=expand(os.path.join(config['outdir'],'align/{sample}_coverage_sub{subsample}.tsv'),sample=SAMPLES,subsample=READ_SUBSAMPLES)
    output:
        combinedcoverage=os.path.join(config['outdir'],config['runname'],'combinedcoverage.tsv')
    log:
        stderr="logs/coverage.err"
    shell:
        """
        {{ echo -e "sample\tsubsample\trname\tstartpos\tendpos\tnumreads\tcovbases\tcoverage\tmeandepth\tmeanbaseq\tmeanmapq";cat {input.coveragestats}; }} > {output.combinedcoverage} 2> {log.stderr}
        """

rule indexbam:
    input:
        bam = '{samplename}.bam'
    output:
        indexedbam = '{samplename}.bam.bai'
    log:
        stdout="logs/bamindex/{samplename}.out",
        stderr="logs/bamindex/{samplename}.err"
    message: "Indexing bam file: {wildcards.samplename}"
    shell:
        """
        samtools index {input.bam} > {log.stdout} 2> {log.stderr}
        """

rule variantcalling:
    input:
        tocall=expand(os.path.join(config['outdir'],'align/{sample}_aln_itrim_sorted.bam'),sample=SAMPLES),
        indexed=expand(os.path.join(config['outdir'],'align/{sample}_aln_itrim_sorted.bam.bai'),sample=SAMPLES)
    params:
        ref=config['reference']
    output:
        vcf=os.path.join(config['outdir'],'pileup',"all_variants_unfilt.vcf.gz")
    log:
        stdout="logs/variantcalling.out",
        stderr="logs/variantcalling.err"
    message: "Calling variants for all samples"
    shell:
        """
        bcftools mpileup -Ou -o variants.bcf -f {params.ref} {input.tocall} 1> {log.stdout} 2> {log.stderr}
        bcftools call --ploidy 1 -vcO z -o {output.vcf} variants.bcf 1>> {log.stdout} 2>> {log.stderr}
        tabix -p vcf {output.vcf} 1>> {log.stdout} 2>> {log.stderr}
	        
	"""

rule variantfilter:
    input:
        vcf={rules.variantcalling.output.vcf}
    output:
        vcf_filt=os.path.join(config['outdir'],'pileup',"all_variants_filt.vcf.gz")
    log:
        stdout="logs/variantfilter.out",
        stderr="logs/variantfilter.err"
    shell:
        """
        bcftools filter -O z -o {output.vcf_filt} -i 'QUAL>10 & DP>10' {input.vcf} 1> {log.stdout} 2> {log.stderr}
        """

rule pileup:
    input:
        tocall=os.path.join(config['outdir'],'align/{sample}_aln_itrim_sorted.bam'),
        indexed=os.path.join(config['outdir'],'align/{sample}_aln_itrim_sorted.bam.bai')
    params:
        ref=config['reference'],
        threshold=0.2,
        depth=20,
        prefix=os.path.join(config['outdir'],'ivar/{sample}_consensus')
    output:
        pileup=os.path.join(config['outdir'],'pileup/{sample}.pileup')
    log:
        stderr="logs/pileup/{sample}.err"
    shell:
        """
        samtools mpileup -aa -A -d 0 -Q 0 -f {params.ref} {input.tocall} 1> {output.pileup} 2> {log.stderr}
        """


rule consensus:
    input:
        pileup=os.path.join(config['outdir'],'pileup/{sample}.pileup')
    params:
        ref=config['reference'],
        threshold=0.2,
        depth=20,
        prefix=os.path.join(config['outdir'],'ivar/{sample}_consensus')
    output:
        consensus=os.path.join(config['outdir'],'ivar/{sample}_consensus.fa')
    log:
        stdout="logs/{sample}/consensus.out",
        stderr="logs/{sample}/consensus.err"
    shell:
        """
        cat {input.pileup} | ivar consensus -t {params.threshold} \
           -m {params.depth} -p {params.prefix} -i {wildcards.sample} \
           1> {log.stdout} 2> {log.stderr}
        """

rule ivariants:
    input:
        pileup=os.path.join(config['outdir'],'pileup/{sample}.pileup')
    params:
        ref=config['reference'],
        threshold=0.2,
        depth=20,
        qual=20,
        prefix=os.path.join(config['outdir'],'ivar/{sample}_ivariants')
    output:
        ivariants=os.path.join(config['outdir'],'ivar/{sample}_ivariants.tsv'),
    resources:
        mem_mb=8000,
        runtime=240,
    log:
        stderr="logs/ivar/{sample}_consensus.err"
    shell:
        """
        cat {input.pileup} | \
         ivar variants -q {params.qual} -r {params.ref} -t {params.threshold} \
           -m {params.depth} -p {params.prefix}  2>&1 >  {log.stderr}        
        """


rule snippy:
    input:
        #read_location=os.path.join(config['outdir'],'{sample}','Unaligned'),
        #indexedref="data/reference.fasta.amb"
        read_location=os.path.join(config['readdir'],'{sample}'),
        indexedref="data/reference.fasta.amb"
    params:
        ref=config['reference']
    container: "docker://staphb/snippy"
    output:
        vcf = os.path.join(config['outdir'],'snippy/snippy_{sample}','snps.vcf'),
        tab = os.path.join(config['outdir'],'snippy/snippy_{sample}','snps.tab')
    log:
        stdout="logs/snippy/{sample}.out",
        stderr="logs/snippy/{sample}.err"
    message: "Running snippy on sample: {wildcards.sample}"
    shell:
        """
        snippy \
            --ref {params.ref} \
            --R1 {input.read_location}/*R1* \
            --R2 {input.read_location}/*R2* \
            --outdir results/snippy/snippy_{wildcards.sample} \
            --force 1> {log.stdout} 2> {log.stderr}
        """

rule snippy_core:
    input:
        snippyout=expand(config['outdir']+'/snippy/snippy_{sample}/snps.tab',sample=SAMPLES),
        indexedref="data/reference.fasta.amb"
    params:
        ref=config['reference'],
        prefix=config['outdir']+'/snippy/core',
        indirs=expand(config['outdir']+'/snippy/snippy_{sample}',sample=SAMPLES)
    container: "docker://staphb/snippy"
    output:
        coreout = expand(config['outdir']+'/snippy/core.{suffix}',suffix=['aln','tab','txt','vcf']) 
    log:
        stdout="logs/"+config['runname']+"/core.out",
        stderr="logs/"+config['runname']+"/core.err"
    message: "Running snippy core"
    shell:
        """
        snippy-core --ref {params.ref}  --prefix {params.prefix} \
            {params.indirs} \
            1> {log.stdout} 2> {log.stderr}
        """

rule evorha:
    input:
        bam=config['outdir']+'/align/{sample}_aln_itrim_sorted.bam',
        idx=config['outdir']+'/align/{sample}_aln_itrim_sorted.bam.bai',
        ref=config['reference']
    params:
        bamln=config['outdir']+'/evorha/{sample}_sorted.bam',
        idxln=config['outdir']+'/evorha/{sample}_sorted.bam.bai',
        prefix=config['outdir']+'/evorha/',
        indirs=expand(config['outdir']+'/snippy/snippy_{sample}',sample=SAMPLES)
    container: "docker://sethnr/pgcoe_evorha:0.01"
    output:
        coreout = config['outdir']+'/evorha/{sample}.hapfreq',
    log:
        stderr="logs/evorha/{sample}.err",
    message: "Running evorha"
    shell:
        """
        if [ ! -f {params.bamln} ]; then
	  ln {input.bam} {params.bamln}
          ln {input.idx} {params.idxln}
	fi
	java -jar /jars/evorha.jar completeAnalysis {input.ref} {params.bamln} 2>&1 >> {log.stderr}
        #java -jar /jars/evorha.jar completeAnalysis {input.ref} {input.bam} 2>&1 >> {log.stderr}
        """
