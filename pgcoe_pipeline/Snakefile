import pandas as pd
import os

configfile: "config/config.yaml"
include: "rules/common.py"

#RUNDATE=config['rundate']
#SAMPLES = set(pd.read_table(config['samples'],header=0,dtype=str,delimiter=',')['Seq_ID']) #change from 'strain' as applicable
#SAMPLES=config['samples'] #un-comment for testing with single samples
#PATHS=set(pd.read_table(config['seq_data'],dtype=str))
#REFERENCE=config['reference']
#HOMEDIR=config['homedir'] #only if you want to set to something other than where this will be run from
#SCRATCH=config['scratchdir']
#PRIMERS=config['primers']
#OUTDIR=config['outdir']


SAMPLES = set(pd.read_table(config['samples'],header=0,dtype=str,delimiter=',')['Seq_ID'])
#SAMPLES = set(pd.read_table(config['samples'],header=0,dtype=str,delimiter=',').loc[lambda df: df['NGS_Date'] == config['rundate'], 'Seq_ID'].tolist())
READ_SUBSAMPLES=set(config['read_subsamples'])

container: "docker://sethnr/pgcoe_bacseq:0.01"



rule all:
    input:
        #coveragestats=expand(os.path.join(config['outdir'],'align/{sample}_coverage_sub{subsample}.tsv'),
	#                     sample=SAMPLES,subsample=READ_SUBSAMPLES),
        # consensuses=expand(os.path.join(config['outdir'],'ivar/{sample}_consensus.fa'),sample=SAMPLES),
        # ivariants=expand(os.path.join(config['outdir'],'ivar/{sample}_ivariants.tsv'),sample=SAMPLES),
        # pileupvcf=os.path.join(config['outdir'],'pileup',"all_variants_filt.vcf.gz"),
        # snippyvcf=config['outdir']+'/snippy/core.vcf',
        combinedcoverage=os.path.join(config['outdir'],config['runname'],'combinedcoverage.tsv'),
        basedepth=config['outdir']+'/'+config['runname']+'/all_depth.txt',
        # metrics=expand(config['outdir']+'/'+config['runname']+'/'+config['runname']+'_{site}_{program}_{metric}.txt',
        #        program=["pileup","snippy"], 
        #        site=["primers","amplicons"],
        #        metric=["meandp","covpc","pi"]),
        snippyvcf=config['outdir']+'/'+config['runname']+'/snippy_all_vars.vcf',
        pileupvcf=config['outdir']+'/'+config['runname']+'/pileup_all_vars.vcf.gz',
        # evorha=expand(config['outdir']+'/evorha/{sample}.hapfreq',sample=SAMPLES),
        #mykrobepredict=expand(config['outdir']+'/mykrobe/{sample}_mykrobe.json',sample=SAMPLES),
        mykrobecombined=config['outdir']+'/mykrobe/combined.csv'
        

rule indexref:
    input:
        reference=config['reference']
    output:
        indexedref="data/reference.fasta.amb"
    log:
    message: "Indexing H37Rv reference"
    shell:
        """
        bwa index {input.reference}
        """

rule align_to_ref:
    input:
        read_location=os.path.join(config['readdir'],'{sample}'),
        indexedref="data/reference.fasta.amb"
    params:
        ref=config['reference']
    resources:
            mem_mb=8000,
            runtime=240,
    output:
        aligned = os.path.join(config['outdir'],'align/{sample}_aligned.bam') # .bam file output of aligned and sorted reads
    log:
        stdout="logs/bwa/{sample}_aln.out",
        stderr="logs/bwa/{sample}_aln.err"
    container: "docker://sethnr/pgcoe_bacseq:0.01"
    message: "Aligning reads to H37Rv and sorting output for sample {wildcards.sample}"
    shell:
        """
        echo "Aligning reads for {wildcards.sample} to H37Rv reference strain\n"
        echo 'bwa mem {params.ref} {input.read_location}/*R1* {input.read_location}/*R2* | samtools view -b -F 4 -F 2048 | samtools sort -o {wildcards.sample}_aln.bam\n' 
        bwa mem {params.ref} {input.read_location}/*R1* {input.read_location}/*R2* | samtools view -b -F 4 -F 2048 | samtools sort -o {output.aligned} >> {log.stdout} 2>> {log.stderr}
        """

rule primerclip:
    input:
        aligned = os.path.join(config['outdir'],'align/{sample}_aligned.bam'),
        primers = config['primers']
    output:
        aln_trimmed= os.path.join(config['outdir'],'align/{sample}_aln_itrim.bam')
    resources:
            mem_mb=8000,
            runtime=1440,
    log:
        stdout="logs/ivar/{sample}_trim.out",
        stderr="logs/ivar/{sample}_trim.err"
    message: "QC and soft-clipping primers using iVar"
    shell:
        """
        ivar trim -i {input.aligned} -b {input.primers} -p {output.aln_trimmed} -e > {log.stdout} 2> {log.stderr}
        """

rule sort:
    input:
        aln_trimmed= os.path.join(config['outdir'],'align/{sample}_aln_itrim.bam')
    output:
        aln_itrim_sorted=os.path.join(config['outdir'],'align/{sample}_aln_itrim_sorted.bam')
    resources:
        mem_mb=16000,
        runtime=180,
	cores=4,
    log:
        stdout="logs/align/{sample}_sort.out",
        stderr="logs/align/{sample}_sort.err"
    message: "Sorting and indexing reads"
    shell:
        """
        samtools sort {input.aln_trimmed} -@ {resources.cores} -o {output.aln_itrim_sorted} > {log.stdout} 2> {log.stderr}
        samtools index {output.aln_itrim_sorted} >> {log.stdout} 2>> {log.stderr}
        """

rule subsample:
    input:
        aln_itrim_sorted= os.path.join(config['outdir'],'align/{sample}_aln_itrim_sorted.bam')
    output:
        subsamp=os.path.join(config['outdir'],'align/{sample}_subsamp{subsample}.bam')
    resources:
        mem_mb=8000,
        runtime=180,
    log:
        stdout="logs/align/{sample}_sub_{subsample}.out",
        stderr="logs/align/{sample}_sub_{subsample}.err",
    message: "Selecting subsample of reads from {wildcards.sample}: {wildcards.subsample}"
    shell:
        """
        samtools view -b -s {wildcards.subsample} {input.aln_itrim_sorted} -o {output.subsamp} 1> {log.stdout} 2> {log.stderr}
        """

rule coverage:
    input:
        subsamp=os.path.join(config['outdir'],'align/{sample}_subsamp{subsample}.bam')
    output:
        coveragestats=os.path.join(config['outdir'],'align/{sample}_coverage_sub{subsample}.tsv')
    resources:
        mem_mb=8000,
        runtime=180,
    params:
        maxdepth=0,
        minmapqual=60,
        minbasequal=13
    log:
        stderr="logs/align/{sample}_sub{subsample}.err"
    message: "Computing coverage of reference for sample {wildcards.sample} with a read subsample fraction of {wildcards.subsample}"
    shell:
        """
        printf '%s\\t%s\\t%s\\t%s\\t%s\\t%s\\t%s\\t%s\\t%s\\t%s\\t%s\\n' {wildcards.sample} {wildcards.subsample} `samtools coverage -d {params.maxdepth} -q {params.minmapqual} -Q {params.minbasequal} --no-header {input.subsamp}` > {output.coveragestats} 2> {log.stderr}
        """

rule mdepth:
    input:
        bams=expand(os.path.join(config['outdir'],'align/{sample}_aln_itrim_sorted.bam'),sample=SAMPLES)
    output:
        config['outdir']+'/'+config['runname']+'/all_depth.txt'
    resources:
        mem_mb=8000,
        runtime=180,
    params:
        maxdepth=0,
        minmapqual=60,
        minbasequal=13
    log:
        stderr="logs/depth/"+config['runname']+".err"
    shell:
        """
        samtools depth -a -H {input.bams} -o {output} 2>&1 >  {log.stderr}
        """


rule combinedcoverage:
    input:
        coveragestats=expand(os.path.join(config['outdir'],'align/{sample}_coverage_sub{subsample}.tsv'),sample=SAMPLES,subsample=READ_SUBSAMPLES)
    output:
        combinedcoverage=os.path.join(config['outdir'],config['runname'],'combinedcoverage.tsv')
    resources:
        mem_mb=8000,
        runtime=180,
    log:
        stderr="logs/coverage.err"
    shell:
        """
        {{ echo -e "sample\tsubsample\trname\tstartpos\tendpos\tnumreads\tcovbases\tcoverage\tmeandepth\tmeanbaseq\tmeanmapq";cat {input.coveragestats}; }} > {output.combinedcoverage} 2> {log.stderr}
        """

rule indexbam:
    input:
        bam = '{samplename}.bam'
    output:
        indexedbam = '{samplename}.bam.bai'
    log:
        stdout="logs/bamindex/{samplename}.out",
        stderr="logs/bamindex/{samplename}.err"
    message: "Indexing bam file: {wildcards.samplename}"
    shell:
        """
        samtools index {input.bam} > {log.stdout} 2> {log.stderr}
        """

rule variantcalling:
    input:
        tocall=expand(os.path.join(config['outdir'],'align/{sample}_aln_itrim_sorted.bam'),sample=SAMPLES),
        indexed=expand(os.path.join(config['outdir'],'align/{sample}_aln_itrim_sorted.bam.bai'),sample=SAMPLES)
    params:
        ref=config['reference']
    resources:
        mem_mb=8000,
        runtime=240,
    output:
        vcf=os.path.join(config['outdir'],'pileup',"all_variants_unfilt.vcf.gz")
    log:
        stdout="logs/variantcalling.out",
        stderr="logs/variantcalling.err"
    message: "Calling variants for all samples"
    shell:
        """
        bcftools mpileup -Ou -o variants.bcf -f {params.ref} {input.tocall} 1> {log.stdout} 2> {log.stderr}
        bcftools call --ploidy 1 -vcO z -o {output.vcf} variants.bcf 1>> {log.stdout} 2>> {log.stderr}
        tabix -p vcf {output.vcf} 1>> {log.stdout} 2>> {log.stderr}
	        
	"""

rule variantfilter:
    input:
        vcf={rules.variantcalling.output.vcf}
    output:
        vcf_filt=os.path.join(config['outdir'],'pileup',"all_variants_filt.vcf.gz")
    resources:
        mem_mb=8000,
        runtime=180,
    log:
        stdout="logs/variantfilter.out",
        stderr="logs/variantfilter.err"
    shell:
        """
        bcftools filter -O z -o {output.vcf_filt} -i 'QUAL>10 & DP>10' {input.vcf} 1> {log.stdout} 2> {log.stderr}
        """

rule pileup:
    input:
        tocall=os.path.join(config['outdir'],'align/{sample}_aln_itrim_sorted.bam'),
        indexed=os.path.join(config['outdir'],'align/{sample}_aln_itrim_sorted.bam.bai')
    params:
        ref=config['reference'],
        threshold=0.2,
        depth=20,
        prefix=os.path.join(config['outdir'],'ivar/{sample}_consensus')
    output:
        pileup=os.path.join(config['outdir'],'pileup/{sample}.pileup')
    log:
        stderr="logs/pileup/{sample}.err"
    shell:
        """
        samtools mpileup -aa -A -d 0 -Q 0 -f {params.ref} {input.tocall} 1> {output.pileup} 2> {log.stderr}
        """


rule consensus:
    input:
        pileup=os.path.join(config['outdir'],'pileup/{sample}.pileup')
    params:
        ref=config['reference'],
        threshold=0.2,
        depth=20,
        prefix=os.path.join(config['outdir'],'ivar/{sample}_consensus')
    output:
        consensus=os.path.join(config['outdir'],'ivar/{sample}_consensus.fa')
    log:
        stdout="logs/{sample}/consensus.out",
        stderr="logs/{sample}/consensus.err"
    shell:
        """
        cat {input.pileup} | ivar consensus -t {params.threshold} \
           -m {params.depth} -p {params.prefix} -i {wildcards.sample} \
           1> {log.stdout} 2> {log.stderr}
        """

rule ivariants:
    input:
        pileup=os.path.join(config['outdir'],'pileup/{sample}.pileup')
    params:
        ref=config['reference'],
        threshold=0.2,
        depth=20,
        qual=20,
        prefix=os.path.join(config['outdir'],'ivar/{sample}_ivariants')
    output:
        ivariants=os.path.join(config['outdir'],'ivar/{sample}_ivariants.tsv'),
    resources:
        mem_mb=8000,
        runtime=240,
    log:
        stderr="logs/ivar/{sample}_consensus.err"
    shell:
        """
        cat {input.pileup} | \
         ivar variants -q {params.qual} -r {params.ref} -t {params.threshold} \
           -m {params.depth} -p {params.prefix}  2>&1 >  {log.stderr}        
        """


rule snippy:
    input:
        #read_location=os.path.join(config['outdir'],'{sample}','Unaligned'),
        #indexedref="data/reference.fasta.amb"
        read_location=os.path.join(config['readdir'],'{sample}'),
        indexedref="data/reference.fasta.amb"
    params:
        ref=config['reference']
    container: "docker://staphb/snippy"
    resources:
            mem_mb=32000,
            runtime=240,
	    cores=4,
    output:
        vcf = os.path.join(config['outdir'],'snippy/snippy_{sample}','snps.vcf'),
        tab = os.path.join(config['outdir'],'snippy/snippy_{sample}','snps.tab')
    log:
        stdout="logs/snippy/{sample}.out",
        stderr="logs/snippy/{sample}.err"
    message: "Running snippy on sample: {wildcards.sample}"
    shell:
        """
        snippy \
            --ref {params.ref} \
            --cpus {resources.cores} \
            --R1 {input.read_location}/*R1* \
            --R2 {input.read_location}/*R2* \
            --outdir results/snippy/snippy_{wildcards.sample} \
            --force 1> {log.stdout} 2> {log.stderr}
        """

rule snippy_core:
    input:
        snippyout=expand(config['outdir']+'/snippy/snippy_{sample}/snps.tab',sample=SAMPLES),
        indexedref="data/reference.fasta.amb"
    params:
        ref=config['reference'],
        prefix=config['outdir']+'/snippy/core',
        indirs=expand(config['outdir']+'/snippy/snippy_{sample}',sample=SAMPLES)
    container: "docker://staphb/snippy"
    resources:
            mem_mb=32000,
            runtime=240,
    output:
        coreout = expand(config['outdir']+'/snippy/core.{suffix}',suffix=['aln','tab','txt','vcf']) 
    log:
        stdout="logs/"+config['runname']+"/core.out",
        stderr="logs/"+config['runname']+"/core.err"
    message: "Running snippy core"
    shell:
        """
        snippy-core --ref {params.ref}  --prefix {params.prefix} \
            {params.indirs} \
            1> {log.stdout} 2> {log.stderr}
        """

rule evorha:
    input:
        bam=config['outdir']+'/align/{sample}_aln_itrim_sorted.bam',
        idx=config['outdir']+'/align/{sample}_aln_itrim_sorted.bam.bai',
    params:
        ref=config['reference'],
        bamln=config['outdir']+'/evorha/{sample}_sorted.bam',
        idxln=config['outdir']+'/evorha/{sample}_sorted.bam.bai',
        prefix=config['outdir']+'/evorha/',
        indirs=expand(config['outdir']+'/snippy/snippy_{sample}',sample=SAMPLES)
    resources:
        mem_mb=8000,
        runtime=1440,
    container: "docker://sethnr/pgcoe_evorha:0.01"
    output:
        coreout = config['outdir']+'/evorha/{sample}.hapfreq',
    log:
        stderr="logs/evorha/{sample}.err",
    message: "Running evorha"
    shell:
        """
	    ln -f {input.bam} {params.bamln}
            ln -f {input.idx} {params.idxln}
            java -jar /jars/evorha.jar completeAnalysis {params.ref} {params.bamln} 2>&1 >> {log.stderr}
        """


rule get_metrics:
    input:
        pileupvcf=os.path.join(config['outdir'],'pileup',"all_variants_filt.vcf.gz"),
        #snippyvcf=config['outdir']+'/snippy/core.vcf',
        combinedcoverage=os.path.join(config['outdir'],config['runname'],'combinedcoverage.tsv'),
        depth=config['outdir']+'/'+config['runname']+'/all_depth.txt',
        primers='data/TBscheme.primer.bed',
        amplicons='data/TBscheme.insert.bed',
    output:
        #expand(config['outdir']+'/'+config['runname']+'/'+config['runname']+'_{site}_{program}_{metric}.tsv',
        #       program=["pileup","snippy"], site=["primers","amplicons"],metric=["meandp","covpc","pi"]),
        #snippyvcf=config['outdir']+'/'+config['runname']+'/snippy_all_vars.vcf',
        expand(config['outdir']+'/'+config['runname']+'/'+config['runname']+'_{site}_{program}_{metric}.tsv',
               program=["pileup"], site=["primers","amplicons"],metric=["meandp","covpc","pi"]),
        pileupvcf=config['outdir']+'/'+config['runname']+'/pileup_all_vars.vcf.gz',
    container: "docker://sethnr/pgcoe_analysis:0.01"
    params:
        spprefix=config['outdir']+'/'+config['runname']+'/'+config['runname']+'_primers_snippy',
        saprefix=config['outdir']+'/'+config['runname']+'/'+config['runname']+'_amplicons_snippy',
        ppprefix=config['outdir']+'/'+config['runname']+'/'+config['runname']+'_primers_pileup',
        paprefix=config['outdir']+'/'+config['runname']+'/'+config['runname']+'_amplicons_pileup',
    shell:
        """
	#cp {{input.snippyvcf}} {{output.snippyvcf}}
        #python scripts/get_pidp_ranges.py --vcf {{input.snippyvcf}} --depth {input.depth} --bed {input.primers} --out {params.spprefix}
        #python scripts/get_pidp_ranges.py --vcf {{input.snippyvcf}} --depth {input.depth} --bed {input.amplicons} --out {params.saprefix}

	cp {input.pileupvcf} {output.pileupvcf}
        python scripts/get_pidp_ranges.py --vcf {input.pileupvcf} --depth {input.depth} --bed {input.primers} --out {params.ppprefix}
        python scripts/get_pidp_ranges.py --vcf {input.pileupvcf} --depth {input.depth} --bed {input.amplicons} --out {params.paprefix}
        """

rule mykrobe:
    input:
        read_location=os.path.join(config['readdir'],'{sample}/Unaligned')
    params:
        outprefix=os.path.join(config['outdir'],'mykrobe/{sample}_mykrobe'),
    output:
        mykrobepredict_json=os.path.join(config['outdir'],'mykrobe/{sample}_mykrobe.json'),
        mykrobepredict_csv=os.path.join(config['outdir'],'mykrobe/{sample}_mykrobe.csv')
    log:
        stdout="logs/mykrobe/{sample}.out",
        stderr="logs/mykrobe/{sample}.err"
    shell:
        """
        mykrobe predict \
        --sample {wildcards.sample} \
        --species tb \
        --output {params.outprefix} \
        --format json_and_csv \
        --seq {input.read_location}/*R1* {input.read_location}/*R2* 1> {log.stdout} 2> {log.stderr}
        """

rule combine_mykrobe:
    input:
        mykrobepredict=expand(config['outdir']+'/mykrobe/{sample}_mykrobe.csv',sample=SAMPLES)
    params:
    output:
        mykrobe_combined=os.path.join(config['outdir'],'mykrobe/combined.csv')
    log:
        stdout="logs/mykrobe/combine.out",
        stderr="logs/mykrobe/combine.err"
    shell:
        """
        echo -e '"sample","drug","susceptibility","variants (dna_variant-AA_variant:ref_kmer_count:alt_kmer_count:conf) [use --format json for more info]","genes (prot_mut-ref_mut:percent_covg:depth) [use --format json for more info]","mykrobe_version","files","probe_sets","genotype_model","kmer_size","phylo_group","species","lineage","phylo_group_per_covg","species_per_covg","lineage_per_covg","phylo_group_depth","species_depth","lineage_depth"' > {output.mykrobe_combined}
        for file in {input.mykrobepredict}; do
            tail -n +2 "$file" >> {output.mykrobe_combined}
        done 2> {log.stderr}
        """